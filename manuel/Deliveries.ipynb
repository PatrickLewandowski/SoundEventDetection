{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deliveries.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PatrickLewandowski/SoundEventDetection/blob/master/manuel/Deliveries.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkKkVC3FozMu"
      },
      "source": [
        "!pip install google-cloud-bigquery-datatransfer\n",
        "!pip install --upgrade google-cloud-storage"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RgWNOyuNWWX",
        "cellView": "form",
        "outputId": "05b7a404-9dd1-45d2-c9f5-3113d1e31c1f"
      },
      "source": [
        "#@title Click run to autentication and setup\n",
        "# Load libraries \n",
        "from google.colab import auth\n",
        "from google.cloud.bigquery import SchemaField\n",
        "from google.cloud import bigquery\n",
        "import time\n",
        "import pandas_gbq\n",
        "from datetime import timedelta, date\n",
        "from google.cloud.exceptions import NotFound\n",
        "import pandas as pd\n",
        "import ipywidgets as widgets\n",
        "import yaml\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "print('Authenticated')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authenticated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZMrxHogtH24"
      },
      "source": [
        "# **Notebook**\n",
        "This notebook has been creaed with the purpose of enabling a smoother creation of resources on the delivery project(telia-ddi-delivery).\n",
        "\n",
        "Considerations:\n",
        "\n",
        "1. The name of the dataset must be written in lower case and include a preffix with the country which is meant to be used. I.E: no_X,fin_x,swe_X,...\n",
        "\n",
        "2. The Dataset_name variable will be used as the ID for the schedule query and the bucket.  \n",
        "\n",
        "3. All the parameters need to be filled-up before running any other cell.  \n",
        "\n",
        "4. The name of the dataset/bucket/schedule query* will be created based on the following pattern:{country}_{ticket_number}_{customer}.\n",
        "\n",
        "5. If the delivery uses schedule query and runs on weekly basis the day of week that runs which be taken from the start_date. I.E Setting up a weekly delivery on the 2020-02-08 means that it would run every Monday.\n",
        "\n",
        "** The schedule query will have extra suffix with the table name at the end {country}_{ticket_number}_{customer}_{table_name}\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTFH-CxlNXW8",
        "cellView": "form"
      },
      "source": [
        "#@title Parameters for creating bucket/dataset/schedule query\n",
        "#Dataset names cannot contain spaces or special characters such as -, &, @, or %.\n",
        "ticket_number = '123421' #@param {type:\"string\"}\n",
        "customer= 'trakkif' #@param {type:\"string\"}\n",
        "country = 'no' #@param [\"swe\", \"no\",'dk','fin','est']\n",
        "Frequency = 'weekly' #@param [\"weekly\", \"daily\",\"monthly\"]\n",
        "Recurrent= 'yes' #@param [\"yes\", \"no\"]\n",
        "tableau= 'yes' #@param [\"yes\", \"no\"]\n",
        "csv= 'yes' #@param [\"yes\", \"no\"]\n",
        "start_date = '2021-03-12' #@param {type:\"date\"}\n",
        "end_date = '2021-03-26' #@param {type:\"date\"}\n",
        "hour = 14 #@param {type:\"slider\", min:0, max:24, step:1}\n",
        "customer=(customer.lower())\n",
        "Dataset_name=f\"{country}_{ticket_number}_{customer}\"\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDs2ieoYJCyw",
        "cellView": "form",
        "outputId": "71f8a85a-49d7-4a3a-d821-f02f059721fc"
      },
      "source": [
        "#@title Create dataset\n",
        "from google.cloud import bigquery\n",
        "\n",
        "\n",
        "Dataset_name=str(Dataset_name).lower()\n",
        "project=\"telia-ddi-delivery\"\n",
        "# Construct a BigQuery client object.\n",
        "client = bigquery.Client(project)\n",
        "\n",
        "# TODO(developer): Set dataset_id to the ID of the dataset to create.\n",
        "# dataset_id = \"{}.your_dataset\".format(client.project)\n",
        "\n",
        "# Construct a full Dataset object to send to the API.\n",
        "dataset = bigquery.Dataset(f\"{project}.{Dataset_name}\")\n",
        "\n",
        "# TODO(developer): Specify the geographic location where the dataset should reside.\n",
        "dataset.location = \"EU\"\n",
        "\n",
        "# Send the dataset to the API for creation, with an explicit timeout.\n",
        "# Raises google.api_core.exceptions.Conflict if the Dataset already\n",
        "# exists within the project.\n",
        "dataset = client.create_dataset(dataset)  # Make an API request.\n",
        "print(\"Created dataset {}.{}\".format(client.project, dataset.dataset_id))\n",
        "\n",
        "# Construct a BigQuery client object.\n",
        "client = bigquery.Client(project)\n",
        "\n",
        "# TODO(developer): Set dataset_id to the ID of the dataset to fetch.\n",
        "# dataset_id = \"your-project.your_dataset\"\n",
        "\n",
        "dataset = client.get_dataset(Dataset_name)  # Make an API request.\n",
        "dataset.labels = {\"frequency\": Frequency, \"recurrent\":Recurrent,\"tableau\":tableau,\"csv\":csv,\"customer\":customer}\n",
        "dataset = client.update_dataset(dataset, [\"labels\"])  # Make an API request.\n",
        "\n",
        "print(\"Labels added to {}\".format(Dataset_name))\n",
        "print(dataset.labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Created dataset telia-ddi-delivery.no_123421_trakkif\n",
            "Labels added to no_123421_trakkif\n",
            "{'frequency': 'weekly', 'recurrent': 'yes', 'tableau': 'yes', 'csv': 'yes', 'customer': 'trakkif'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcnB-UO_fIS4",
        "cellView": "form",
        "outputId": "fddee82b-9345-490a-f8ba-5e0b5db173a7"
      },
      "source": [
        "#@title Modify labels of the dataset\n",
        "from google.cloud import bigquery\n",
        "\n",
        "\n",
        "Dataset_name=str(Dataset_name).lower()\n",
        "project=\"telia-ddi-delivery\"\n",
        "\n",
        "client = bigquery.Client(project)\n",
        "\n",
        "# TODO(developer): Set dataset_id to the ID of the dataset to fetch.\n",
        "# dataset_id = \"your-project.your_dataset\"\n",
        "\n",
        "dataset = client.get_dataset(Dataset_name)  # Make an API request.\n",
        "dataset.labels = {\"frequency\": Frequency, \"recurrent\":Recurrent,\"tableau\":tableau,\"csv\":csv,\"customer\":customer}\n",
        "dataset = client.update_dataset(dataset, [\"labels\"])  # Make an API request.\n",
        "\n",
        "print(\"Labels added to {}\".format(Dataset_name))\n",
        "print(dataset.labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Labels added to test_323232\n",
            "{'frequency': 'weekly', 'recurrent': 'yes', 'tableau': 'yes', 'one_off': 'yes', 'csv': 'yes', 'customer': 'trakkif'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIOZo_hMNPsA",
        "cellView": "form",
        "outputId": "81de09b0-03dc-433d-b5b9-be30c6bfbc59"
      },
      "source": [
        "#@title Create bucket\n",
        "from google.cloud import storage\n",
        "import pprint\n",
        "\n",
        "Dataset_name=str(Dataset_name).lower()\n",
        "project=\"telia-ddi-delivery\"\n",
        "# Instantiates a client\n",
        "storageClient = storage.Client(project)\n",
        "bucket = storageClient.bucket(Dataset_name)\n",
        "#bucket.storage_class = \"COLDLINE\"\n",
        "bucket.create(location=\"EU\",)\n",
        "print(\"Bucket {} created.\".format(Dataset_name))\n",
        "\n",
        "storage_client = storage.Client(project)\n",
        "\n",
        "bucket = storage_client.get_bucket(Dataset_name)\n",
        "bucket.labels = {\"frequency\": Frequency, \"recurrent\":Recurrent,\"tableau\":tableau,\"csv\":csv,\"customer\":customer}\n",
        "bucket.iam_configuration.uniform_bucket_level_access_enabled = True\n",
        "bucket.patch()\n",
        "\n",
        "print(\"Updated labels on {}.\".format(Dataset_name))\n",
        "pprint.pprint(bucket.labels)\n",
        "\n",
        "storage_client = storage.Client(project)\n",
        "bucket = storage_client.get_bucket(Dataset_name)\n",
        "bucket.iam_configuration.uniform_bucket_level_access_enabled = True\n",
        "bucket.patch()\n",
        "\n",
        "#print(\n",
        " #   \"Uniform bucket-level access was enabled for {}.\".format(bucket.name)\n",
        "#)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bucket no_123421_trakkif created.\n",
            "Updated labels on no_123421_trakkif.\n",
            "{'csv': 'yes',\n",
            " 'customer': 'trakkif',\n",
            " 'frequency': 'weekly',\n",
            " 'recurrent': 'yes',\n",
            " 'tableau': 'yes'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3U_Zum0gOeII",
        "cellView": "form",
        "outputId": "36746b96-44a9-4648-b15d-ae200d00cf04"
      },
      "source": [
        "#@title Modify labels of the bucket\n",
        "from google.cloud import storage\n",
        "import pprint\n",
        "\n",
        "\n",
        "Dataset_name=str(Dataset_name).lower()\n",
        "project=\"telia-ddi-delivery\"\n",
        "# Instantiates a client\n",
        "storage_client = storage.Client(project)\n",
        "\n",
        "bucket = storage_client.get_bucket(Dataset_name)\n",
        "bucket.labels = {\"frequency\": Frequency, \"recurrent\":Recurrent,\"tableau\":tableau,\"csv\":csv,\"customer\":customer}\n",
        "bucket.patch()\n",
        "print(\"Updated labels on {}.\".format(bucket.name))\n",
        "pprint.pprint(bucket.labels)\n",
        "\n",
        "\n",
        "storage_client = storage.Client(project)\n",
        "bucket = storage_client.get_bucket(Dataset_name)\n",
        "bucket.iam_configuration.uniform_bucket_level_access_enabled = True\n",
        "bucket.patch()\n",
        "\n",
        "#print(\n",
        " #   \"Uniform bucket-level access was enabled for {}.\".format(bucket.name)\n",
        "#)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated labels on test_1234412211231.\n",
            "{'csv': 'yes',\n",
            " 'customer': 'trakkif',\n",
            " 'frequency': 'weekly',\n",
            " 'one_off': 'yes',\n",
            " 'recurrent': 'yes',\n",
            " 'tableau': 'yes'}\n",
            "Uniform bucket-level access was enabled for test_1234412211231.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "yykJXGEHIK0v"
      },
      "source": [
        "#@title Add users to the bucket\n",
        "#Dataset names cannot contain spaces or special characters such as -, &, @, or %.\n",
        "email_list = [\"maria.isaksson@reitanconvenience.se\" ]#@param {type:\"raw\"}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qW2pEaK0I1RG",
        "cellView": "form",
        "outputId": "6ca467f8-9ab9-4f4b-aa4b-a655bfad225f"
      },
      "source": [
        "#@title Click run to print a yaml file and user template for the bucket\n",
        "\n",
        "#empty variable for email list iteration\n",
        "email = \"\"\n",
        "index = 0\n",
        "\n",
        "#loop through email list specified, use inserted parameters\n",
        "for email in email_list:\n",
        "    file_name = email.split('@')[0].lower() + '.yml'\n",
        "    index += 1\n",
        "    output = f\"\"\"meta: 'Access bucket'\n",
        "gcs:\n",
        "  - bucket: \"{Dataset_name}\"\n",
        "    expires: \"{end_date}\"\n",
        "    editor: true\n",
        "email: \"{email}\"\n",
        "\"\"\"\n",
        "    print(output)\n",
        "\n",
        " \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "meta: 'Access bucket'\n",
            "gcs:\n",
            "  - bucket: \"no_123421_trakkif\"\n",
            "    expires: \"2021-03-03\"\n",
            "    editor: true\n",
            "email: \"maria.isaksson@reitanconvenience.se\"\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "h7lapKdTsgGq"
      },
      "source": [
        "#@title Click run to create a yaml file and user template for the bucket\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "#empty variable for email list iteration\n",
        "email = \"\"\n",
        "index = 0\n",
        "\n",
        "#loop through email list specified, use inserted parameters\n",
        "for email in email_list:\n",
        "    file_name = email.split('@')[0].lower() + '.yml'\n",
        "    index += 1\n",
        "    output = f\"\"\"meta: 'Access bucket'\n",
        "gcs:\n",
        "  - bucket: \"{Dataset_name}\"\n",
        "    expires: \"{end_date}\"\n",
        "    editor: true\n",
        "email: \"{email}\"\n",
        "\"\"\"\n",
        "    #print(output)\n",
        "    #make the yml file here using file_name and output\n",
        "    with open(f'/content/gdrive/My Drive/{file_name}', 'w') as outfile:\n",
        "      print(outfile)\n",
        "      #print(yaml.safe_load(yaml.dump(output,default_flow_style=False)))\n",
        "      write = yaml.safe_load(yaml.dump(output,default_flow_style=False))\n",
        "      outfile.write(write)\n",
        "      print(f\"Wrote file {file_name} to Drive\")\n",
        "      time.sleep(2)\n",
        "      print(f\"File {index} done: {file_name}\")\n",
        "      print()\n",
        " \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "so5n-grz64bz"
      },
      "source": [
        "# **Schedule queries**\n",
        "The main purpose of the schedule queries is to grant you the possiblity of creating recurrent deliveries either way on Tableau or CSV.\n",
        "\n",
        "Considerations:\n",
        "\n",
        "\n",
        "1.   The schedules query must have on top of the query a create or replace table statment to recreate the table.\n",
        "\n",
        "2.   If the frequency is daily the query shouldn't run more than 500GB.\n",
        "\n",
        "3.   If the frequency is weekly the query shouldn't run more than 2TB.\n",
        "\n",
        "4.   The schedule queries can generate CSV files in bucket by including the following chunk of code at the top of the query:\n",
        "\n",
        "5. Please set-up the table name and file name parameter in case that the delivery requires CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "zmYq5pT1Zn1b",
        "outputId": "20ae09c2-0e1a-498a-c1a3-c9b54746bd34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "#@title Parameters for the schedule query\n",
        "#Dataset names cannot contain spaces or special characters such as -, &, @, or %.\n",
        "table_name = 'INPUT_TABLE_NAME' #@param {type:\"string\"}\n",
        "file_name = 'INPUT_FILE_NAME' #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-a7054dc6fb9f>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    file_name(Just if needed) = 'INPUT_FILE_NAME' #@param {type:\"string\"}\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pBYr4YN8TO-"
      },
      "source": [
        "##########Example SQ with CSV############\n",
        "###Write file_name & table_name\n",
        "###DON'T CHANGE THE dataset_name variable\n",
        "### Fill-up table_name parameters & file_name###\n",
        "Dataset_name=str(Dataset_name).lower()\n",
        "query_string = f\"\"\"\n",
        "/* ddi-meta\n",
        "project_id: telia-ddi-delivery\n",
        "source_dataset: {Dataset_name}\n",
        "source_table: {table_name}\n",
        "output_destination_uri: gs://{Dataset_name}/{file_name}_*.csv\n",
        "*/\n",
        "create or replace table `telia-ddi-delivery.{Dataset_name}.{table_name}`\n",
        "as\n",
        "#Example query, pls replace this part of the code with your actual query#\n",
        "SELECT *\n",
        "FROM `telia-ddi-est-dev.Estonia_COVID.covidhomezone`;\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Aeh1fwk8DLV"
      },
      "source": [
        "The table name and the file name need to be modified accordingly to the deliver."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghOykoYFsGzD"
      },
      "source": [
        "##########Example SQ without CSV############\n",
        "###Write file_name & table_name\n",
        "###DON'T CHANGE THE dataset_name variable\n",
        "Dataset_name=str(Dataset_name).lower()\n",
        "table_name=\"INPUT_TABLE_NAME\"# To be changed\n",
        "query_string = f\"\"\"\n",
        "\n",
        "create or replace table `telia-ddi-delivery.{Dataset_name}.{table_name}`\n",
        "as\n",
        "#Example query, pls replace this part of the code with your actual query#\n",
        "SELECT\n",
        "  CURRENT_TIMESTAMP() as current_time,\n",
        "  @run_time as intended_run_time,\n",
        "  @run_date as intended_run_date,\n",
        "  17 as some_integer;\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oP1V-MBEiWLF",
        "cellView": "form"
      },
      "source": [
        "#@title Create schedule query\n",
        "from google.cloud import bigquery_datatransfer\n",
        "import time\n",
        "transfer_client = bigquery_datatransfer.DataTransferServiceClient()\n",
        "from google.protobuf.timestamp_pb2 import Timestamp\n",
        "\n",
        "import datetime\n",
        "date_time_str = f'{start_date} {hour}:00:00.0'\n",
        "print(f\"Starting date: {date_time_str} \")\n",
        "date_time_obj = datetime.datetime.strptime(date_time_str, '%Y-%m-%d %H:%M:%S.%f')\n",
        "start_timestamp=datetime.datetime.timestamp(date_time_obj)\n",
        "start_timestamp = Timestamp(                    seconds=int(start_timestamp))\n",
        "\n",
        "\n",
        "day_of_week=date_time_obj.strftime('%A')\n",
        "\n",
        "date_time_str = f'{end_date} {hour}:00:00.0'\n",
        "print(f\"end date: {date_time_str} \")\n",
        "date_time_obj = datetime.datetime.strptime(date_time_str, '%Y-%m-%d %H:%M:%S.%f')\n",
        "end_timestamp=datetime.datetime.timestamp(date_time_obj)\n",
        "end_timestamp = Timestamp(                    seconds=int(end_timestamp))\n",
        "\n",
        "# The project where the query job runs is the same as the project\n",
        "# containing the destination dataset.\n",
        "project_id = \"telia-ddi-delivery\"\n",
        "Dataset_name=str(Dataset_name).lower()\n",
        "\n",
        "# Use standard SQL syntax for the query.\n",
        "\n",
        "if \"daily\" in Frequency:\n",
        "  schedule=f\"every 24 hours\"\n",
        "elif \"weekly\":\n",
        "  schedule=f\"every {day_of_week} {hour}:00\"\n",
        "else:\n",
        "  schedule=f\"1 of month 00:00\"  \n",
        "notification_pubsub_topic=\"\"\n",
        "if \"ddi-meta\" in query_string:\n",
        "  notification_pubsub_topic=\"projects/telia-ddi-delivery/topics/bq-export-table-topic\"\n",
        "\n",
        "\n",
        "\n",
        "transfer_client = bigquery_datatransfer.DataTransferServiceClient()\n",
        "project_id = \"telia-ddi-delivery\"\n",
        "destination_dataset_id=\"\"\n",
        "parent = transfer_client.common_project_path(project_id)\n",
        "transfer_config = bigquery_datatransfer.TransferConfig(\n",
        "  destination_dataset_id=\"\",\n",
        "  display_name=f\"{Dataset_name}_{table_name}\",\n",
        "  data_source_id=\"scheduled_query\",\n",
        "  params={\n",
        "      \"query\": query_string,\n",
        "  },\n",
        "  schedule=schedule,\n",
        "  notification_pubsub_topic=notification_pubsub_topic,\n",
        "  dataset_region=\"EU\",\n",
        "  email_preferences={\"enable_failure_email\":True},\n",
        "  schedule_options= {\"start_time\":start_timestamp,\"end_time\":end_timestamp} \n",
        ")\n",
        "\n",
        "\n",
        "parent = \"projects/telia-ddi-delivery/locations/EU\"\n",
        "\n",
        "transfer_config = transfer_client.create_transfer_config(\n",
        "    bigquery_datatransfer.CreateTransferConfigRequest(\n",
        "        parent=parent, transfer_config=transfer_config,\n",
        "    )\n",
        ")\n",
        "print(\"Created scheduled query '{}'\".format(transfer_config.name))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAiFye2mP7wf",
        "cellView": "form"
      },
      "source": [
        "#@title If the above does not work run this and follow the instructions\n",
        "\n",
        "!gcloud auth application-default login  --no-launch-browser\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "eTXJ-oY0uww9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}